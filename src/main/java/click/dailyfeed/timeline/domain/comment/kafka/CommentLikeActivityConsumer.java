package click.dailyfeed.timeline.domain.comment.kafka;

import click.dailyfeed.code.domain.content.comment.dto.CommentDto;
import click.dailyfeed.code.global.kafka.type.DateBasedTopicType;
import click.dailyfeed.timeline.domain.comment.document.CommentLikeActivity;
import click.dailyfeed.timeline.domain.comment.mapper.TimelineCommentMapper;
import click.dailyfeed.timeline.domain.comment.redis.CommentLikeActivityEventRedisService;
import click.dailyfeed.timeline.domain.comment.repository.mongo.CommentLikeActivityMongoRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Propagation;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDate;
import java.time.format.DateTimeFormatter;
import java.util.List;

@Slf4j
@RequiredArgsConstructor
@Component
public class CommentLikeActivityConsumer {
    private final CommentLikeActivityMongoRepository commentLikeActivityMongoRepository;
    private final CommentLikeActivityEventRedisService commentLikeActivityEventRedisService;
    private final TimelineCommentMapper timelineCommentMapper;

    @KafkaListener(
            topicPattern = DateBasedTopicType.COMMENT_LIKE_ACTIVITY_PATTERN,
            groupId = "comment-like-activity-consumer-group-timeline-svc",
            containerFactory = "commentLikeActivityKafkaListenerContainerFactory"
    )
    public void consumeAllPostActivityEvents(
            @Payload CommentDto.LikeActivityEvent event,
            @Header(KafkaHeaders.RECEIVED_TOPIC) String topic,
            @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
            @Header(KafkaHeaders.OFFSET) long offset,
            Acknowledgment acknowledgment) {

        // ì˜¤í”„ì…‹ ë° ì´ë²¤íŠ¸ ì •ë³´ ë¡œê¹…
        log.debug("ğŸ“¨ Consuming message - Topic: {}, Partition: {}, Offset: {}, PostId: {}, EventType: {}",
                topic, partition, offset, event.getCommentId(), event.getCommentLikeType());

        try{
            // í† í”½ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
            String dateStr = DateBasedTopicType.COMMENT_LIKE_ACTIVITY.extractDateFromTopicName(topic);

            if (dateStr != null) {
                // ë‚ ì§œ í˜•ì‹ ê²€ì¦ (yyyyMMdd í˜•ì‹ì¸ì§€ í™•ì¸)
                if (dateStr.matches("\\d{8}")) { // ë‚ ì§œ íƒ€ì… ì²˜ë¦¬
                    processEventByDate(event, dateStr);
                }
                else{
                    // ë‚ ì§œ íƒ€ì…ì´ ì•„ë‹Œ ë‹¤ë¥¸ íƒ€ì…ì˜ í† í”½ ë¶„ë¥˜
                }
            }

            // ë©”ì‹œì§€ ì²˜ë¦¬ ì„±ê³µ í›„ ì˜¤í”„ì…‹ ì»¤ë°‹
            acknowledgment.acknowledge();
            log.debug("âœ… Offset committed - Topic: {}, Partition: {}, Offset: {}", topic, partition, offset);

        } catch (Exception e) {
            log.error("âŒ Failed to process message - Topic: {}, Partition: {}, Offset: {}, Error: {}",
                    topic, partition, offset, e.getMessage(), e);
            // ì‹¤íŒ¨ ì‹œ ì˜¤í”„ì…‹ ì»¤ë°‹í•˜ì§€ ì•ŠìŒ - ì¬ì‹œì‘ ì‹œ ì´ ë©”ì‹œì§€ë¶€í„° ë‹¤ì‹œ ì²˜ë¦¬
            // DLQë¡œ ë³´ë‚´ê±°ë‚˜ ì¬ì‹œë„ ë¡œì§ êµ¬í˜„ ê°€ëŠ¥
        }
    }

    /**
     * ë‚ ì§œë³„ ì´ë²¤íŠ¸ ì²˜ë¦¬
     */
    private void processEventByDate(CommentDto.LikeActivityEvent event, String dateStr) {
        LocalDate eventDate = LocalDate.parse(dateStr, DateTimeFormatter.ofPattern("yyyyMMdd"));
        LocalDate today = LocalDate.now();

        if (eventDate.equals(today)) {
            cachingPostActivityEvent(event);
        } else if (eventDate.isBefore(today)) {
            if(eventDate.isAfter(today.minusDays(2))) {
                cachingPostActivityEvent(event);
            }
            else{
                // ì ‘ë¯¸ì‚¬ê°€ yyyyMMdd í˜•ì‹ì´ ì•„ë‹Œ ë‹¤ë¥¸ í˜•ì‹ì˜ í† í”½ì¼ ê²½ìš° ì´ê³³ì—ì„œ ì²˜ë¦¬ (ìš´ì˜ì„ ìœ„í•œ íŠ¹ì • ìš©ë„)
            }
        } else {
            log.info("ë¯¸ë˜ì—ì„œ ì˜¤ì…¨êµ°ìš”, 10ë…„ ë’¤ì— ì‚¼ì„±ì „ì ì–¼ë§ˆì—ìš”?");
        }
    }

    private void cachingPostActivityEvent(CommentDto.LikeActivityEvent event) {
        // 1) Message read
        if (event == null) {
            return;
        }

        // 2) cache put
        commentLikeActivityEventRedisService.rPushEvent(event);
    }

    @Transactional(propagation = Propagation.REQUIRED, rollbackFor = Exception.class)
    @Scheduled(fixedRate = 1000)
    public void insertMany(){
        // 1ì´ˆì— í•œë²ˆì”© ë™ì‘ (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ 5ì´ˆ í›„ë¶€í„°)
        int processedBatches = 0;

        // 1ì´ˆì— í•œë²ˆì”© ë™ì‘
        while(true){
            List<CommentDto.LikeActivityEvent> eventList = commentLikeActivityEventRedisService.lPopList();
            if(eventList == null || eventList.isEmpty()){
                break;
            }
            try{
                log.info("ğŸ“¦ Processing batch #{} - size: {}", ++processedBatches, eventList.size());
                List<CommentLikeActivity> insertList = eventList
                        .stream()
                        .map(ev -> timelineCommentMapper.fromCommentLikeActivityEvent(ev))
                        .toList();

                commentLikeActivityMongoRepository.saveAll(insertList);
                log.debug("âœ… Successfully saved {} events to MongoDB", eventList.size());
            }
            catch (Exception e){
                log.error("âŒ Failed to save batch to MongoDB", e);

                // kafka DLQ publish
                // (TODO êµ¬í˜„ ì˜ˆì •)

                // redis DLQ caching
                commentLikeActivityEventRedisService.rPushDeadLetterEvent(eventList);
                log.info("ğŸ“® Moved {} events to dead letter queue", eventList.size());
            }
        }
    }
}
